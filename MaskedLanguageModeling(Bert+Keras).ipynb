{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaskedLanguageModeling(Bert+Keras).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "feAf-qQhQI1V"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from dataclasses import dataclass #This module provides a decorator and functions for automatically adding generated special methods such as __init__() and __repr__() to user-defined classes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob #Returns a list of files that match the given pattern(s).\n",
        "import re\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjSgT8bbQ5EB"
      },
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "  MAX_LEN=256\n",
        "  BATCH_SIZE=32\n",
        "  LR=0.001\n",
        "  VOCAB_SIZE=30000\n",
        "  EMBED_DIM=128\n",
        "  NUM_HEAD=8\n",
        "  FF_DIM=128\n",
        "  NUM_LAYERS=1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiDbuV6aSLIl"
      },
      "source": [
        "config=Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nnb5VRDSNwJ",
        "outputId": "8257020c-4318-491e-9c18-b06cc8d1c870"
      },
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz #transferring data specified with URL syntax\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  60.5M      0  0:00:01  0:00:01 --:--:-- 60.5M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ziw9Kc7PSQ-V"
      },
      "source": [
        "def get_text_list_from_files(files):\n",
        "  text_list=[]\n",
        "  for name in files:\n",
        "    with open(name) as f:\n",
        "      for line in f:\n",
        "        text_list.append(line)\n",
        "  return text_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9W-4p5kTVNd"
      },
      "source": [
        "def get_data_from_text_files(folder_name):\n",
        "  pos_files=glob.glob(\"aclImdb/\"+folder_name+\"/pos/*.txt\")\n",
        "  pos_texts=get_text_list_from_files(pos_files)\n",
        "  neg_files=glob.glob(\"aclImdb/\"+folder_name+\"/neg/*.txt\")\n",
        "  neg_texts=get_text_list_from_files(neg_files)\n",
        "  df=pd.DataFrame({\"review\":pos_texts+neg_texts,\"sentiment\":[0]*len(pos_texts)+[1]*len(neg_texts),})\n",
        "  df=df.sample(len(df)).reset_index(drop=True)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arEZAJOMUZQ8"
      },
      "source": [
        "train_df=get_data_from_text_files(\"train\")\n",
        "test_df=get_data_from_text_files(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZF_weu4YggJ"
      },
      "source": [
        "all_data = train_df.append(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Yk3yw_twVvbc",
        "outputId": "fe81d436-abc0-4a2a-8ede-969d99fa1c60"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is a very grim, hard hitting, even brutal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was this supposed to be? A remake of Fish...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's hard to rate films like this, because do ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All I can say is, first movie this season that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gundam Wing to me happens to be a good anime. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>This movie is wonderful. It always has been al...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>The French film \"Extension Du Domaine De La Lu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>Three Russian aristocrats soak up the decadenc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>This movie was made in 1948, but it still ring...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>Wow, I can't believe i'm the first and only on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "0      This is a very grim, hard hitting, even brutal...          0\n",
              "1      What was this supposed to be? A remake of Fish...          1\n",
              "2      It's hard to rate films like this, because do ...          0\n",
              "3      All I can say is, first movie this season that...          0\n",
              "4      Gundam Wing to me happens to be a good anime. ...          0\n",
              "...                                                  ...        ...\n",
              "24995  This movie is wonderful. It always has been al...          0\n",
              "24996  The French film \"Extension Du Domaine De La Lu...          1\n",
              "24997  Three Russian aristocrats soak up the decadenc...          1\n",
              "24998  This movie was made in 1948, but it still ring...          0\n",
              "24999  Wow, I can't believe i'm the first and only on...          0\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_U4_bk9Vosu"
      },
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase=tf.strings.lower(input_data)\n",
        "  stripped_html=tf.strings.regex_replace(lowercase,\"<br />\",\" \")\n",
        "  return tf.strings.regex_replace(stripped_html,\"[%s]\"%re.escape(\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\"),\"\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqUtl1KzXXiX",
        "outputId": "4e86f9b2-cb87-4f26-b2ab-4730c4f59953"
      },
      "source": [
        "special_tokens=[\"[MASK]\"]\n",
        "len(special_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-maHAvHvWpzi"
      },
      "source": [
        "def get_vectorize_layer(texts,vocab_size,max_seq,special_tokens=[\"[MASK\"]):\n",
        "  vectorize_layer=TextVectorization(max_tokens=vocab_size,output_mode=\"int\",standardize=custom_standardization,output_sequence_length=max_seq)\n",
        "  vectorize_layer.adapt(texts)\n",
        "  vocab=vectorize_layer.get_vocabulary()\n",
        "  vocab=vocab[2:vocab_size-len(special_tokens)]+[\"[mask]\"]\n",
        "  vectorize_layer.set_vocabulary(vocab)\n",
        "  return vectorize_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "THVltl8KYid_",
        "outputId": "db5b0ef2-5cfd-47a6-fc70-0ca5d1dd3849"
      },
      "source": [
        "all_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is a very grim, hard hitting, even brutal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was this supposed to be? A remake of Fish...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's hard to rate films like this, because do ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All I can say is, first movie this season that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gundam Wing to me happens to be a good anime. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>This film is a completely inaccurate depiction...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>&lt;br /&gt;&lt;br /&gt;Well-known comedians meekly admit ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>I got subjected to this pile one Wednesday aft...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>I've discovered this movie accidentally and it...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>In yet another case of misleading marketing, t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "0      This is a very grim, hard hitting, even brutal...          0\n",
              "1      What was this supposed to be? A remake of Fish...          1\n",
              "2      It's hard to rate films like this, because do ...          0\n",
              "3      All I can say is, first movie this season that...          0\n",
              "4      Gundam Wing to me happens to be a good anime. ...          0\n",
              "...                                                  ...        ...\n",
              "24995  This film is a completely inaccurate depiction...          1\n",
              "24996  <br /><br />Well-known comedians meekly admit ...          0\n",
              "24997  I got subjected to this pile one Wednesday aft...          1\n",
              "24998  I've discovered this movie accidentally and it...          0\n",
              "24999  In yet another case of misleading marketing, t...          1\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feP2LtEkXNBw"
      },
      "source": [
        "vectorize_layer=get_vectorize_layer(all_data.review.values.tolist(),config.VOCAB_SIZE,config.MAX_LEN,special_tokens=[\"[mask]\"],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8sVPfcxYm5w",
        "outputId": "92579989-e135-4be2-97e9-2175fb2d084e"
      },
      "source": [
        "print(all_data.review.values.tolist()) #convert values and append in the list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsb163RBYqEP"
      },
      "source": [
        "mask_token_id=vectorize_layer([\"mask\"]).numpy()[0][0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP75mXFtaMQG",
        "outputId": "7a7bb6d1-0a36-49c2-8cb9-318fbce858e4"
      },
      "source": [
        "mask_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2368"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSGp7y5XbFGE"
      },
      "source": [
        "list1=[1,2,3]+[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxgDvbmKbOBa",
        "outputId": "73f04a8d-e823-4c57-cf44-09bd2f98302b"
      },
      "source": [
        "list1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cOMLk0sbmwo",
        "outputId": "cd650995-0b2d-416b-e352-5463b2926b5f"
      },
      "source": [
        "vectorize_layer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7fc048da77b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KTvNvLAbO24"
      },
      "source": [
        "def encode(texts):\n",
        "  encoded_texts=vectorize_layer(texts)\n",
        "  return encoded_texts.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TayV15YEbhMC"
      },
      "source": [
        "def get_masked_input_and_labels(encoded_texts):\n",
        "  inp_mask=np.random.rand(*encoded_texts.shape)<0.15\n",
        "  inp_mask[encoded_texts<=2]=False\n",
        "  labels=-1*np.ones(encoded_texts.shape,dtype=int)\n",
        "  labels[inp_mask]=encoded_texts[inp_mask] \n",
        "  encoded_texts_masked=np.copy(encoded_texts)\n",
        "  inp_mask_2mask=inp_mask&(np.random.rand(*encoded_texts.shape)<0.90) \n",
        "#  print(encoded_texts_masked[0])\n",
        "#  print(encoded_texts_masked[1])\n",
        "#  print(labels[0])\n",
        "#  print(labels[1])\n",
        "  print(inp_mask_2mask[0])\n",
        "  print(inp_mask_2mask[1])\n",
        "  encoded_texts_masked[inp_mask_2mask]=mask_token_id\n",
        " # print(encoded_texts_masked[0])\n",
        " # print(encoded_texts_masked[1])\n",
        "  inp_mask_2random=inp_mask_2mask & (np.random.rand(*encoded_texts.shape)<1/9)\n",
        "  encoded_texts_masked[inp_mask_2random]=np.random.randint(3,mask_token_id,inp_mask_2random.sum())\n",
        "  sample_weights=np.ones(labels.shape)\n",
        "  sample_weights[labels==-1]=0\n",
        "  y_labels=np.copy(encoded_texts)\n",
        "  return encoded_texts_masked,y_labels,sample_weights  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Um1PONucR56",
        "outputId": "64f99911-863d-4081-c684-25123c0d997b"
      },
      "source": [
        "a=np.random.rand(3,3)<0.15\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False],\n",
              "       [ True, False, False],\n",
              "       [False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uMaWy78cfmR"
      },
      "source": [
        "a[0][1]=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_0Lk3Pqc4no"
      },
      "source": [
        "a[1][2]=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-dyspDDc40p",
        "outputId": "2c1cf465-9488-4edd-f5ea-6880d8ca3d65"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False],\n",
              "       [ True, False, False],\n",
              "       [False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggPuwx2i2BT8"
      },
      "source": [
        "x_train=encode(train_df.review.values)\n",
        "y_train=train_df.sentiment.values\n",
        "train_classifier_ds=(tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(1000).batch(config.BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXThQ3Xa3QqD",
        "outputId": "665805ce-12c6-46da-a7df-d58b311f8b81"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   11,     7,     4, ...,     0,     0,     0],\n",
              "       [   48,    13,    11, ...,     0,     0,     0],\n",
              "       [   29,   263,     6, ...,  1263,    23,   179],\n",
              "       ...,\n",
              "       [  283,  1511, 17753, ...,     0,     0,     0],\n",
              "       [   11,    17,    13, ...,     0,     0,     0],\n",
              "       [ 1476,    10,   173, ...,     3,     1,   452]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulcAerXJ3Wok",
        "outputId": "2e985e6d-e0e7-4905-8e9b-bc2b3404008c"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgMuaakw3YWY"
      },
      "source": [
        "x_test=encode(test_df.review.values)\n",
        "y_test=test_df.sentiment.values\n",
        "test_classifier_ds=tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(config.BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceGwnfPl3ueV"
      },
      "source": [
        "test_raw_classifier_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_df.review.values, y_test)\n",
        ").batch(config.BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YirEPHpC3yyq",
        "outputId": "c6e0fe91-f07d-4e5f-e7e2-99e97518c1b2"
      },
      "source": [
        "test_raw_classifier_ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck8wkB6q4Bmr",
        "outputId": "ae6c0350-45ad-486b-efac-625eb54a1899"
      },
      "source": [
        "print(all_data.review.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Japanese indie film with humor and philosophy where the three main characters run literally almost through the entire film, chasing each other due to strange circumstances and comical coincidence. As they are running, we see what is going on in their minds and how they got where they are at the moment. The act of running is a metaphor for these down-on-their luck people's lives. In some way, what they're really chasing for is not what they were originally chasing, but for meaning in their lives and an escape from their personal problems and broken dreams. Running makes them all feel truly alive. The big life-altering running adventure comes to an end when they accidentally get in the middle of something big, violent, and so absurd that it's funny in a clever way. One of my favorite films of all time by genius director Sabu.\"\n",
            " 'This must have been one of the worst movies I have ever seen.<br /><br />I have to disagree with another commenter, who said the special effects were okay. I found them pretty bad: it just wasn\\'t realistic and they were so fake that it just distracted from the actual story.<br /><br />Maybe that distraction is the reason that I did not fully understand the story. The archaeologists are looking for \"the set\". They do not bother to tell what set, or what is so special about it. That also makes it unclear why they search for it in California, while the intro of the movie takes place in ancient Egypt.<br /><br />If you\\'re shooting a movie that takes place in the desert, take the effort to actually go to the desert. The beginning - the ancient ceremony - looks like it was shot inside a studio instead of a desert.<br /><br />The action-level was constant throughout the movie, no ups and downs, no climax. It made the movie look short, and that\\'s certainly a pro for this particular movie.'\n",
            " 'FORGET CREDIBILITY<br /><br />You must not expect credibility with action movies where the superhero has to perform an endless string of unbelievable feats, being trodden upon in the process but recovering at lightning speed, and transforming innocuous gadgets in lethal weapons... especially when Renny Harlin is directing.<br /><br />\"CLIFFHANGER \" is no exception. But the movie has numerous assets : breathtaking scenery gorgeously photographed, stunning special and visual effects ( the first five minutes are gripping and give the tone of the film ), excellent musical score, welcome attempts at levity to relieve some of the tension, and a solid cast : two heroes ( Stallone, star and cowriter, has the lion\\'s share of the footage, but the excellent Michael Rooker more than stands his ground ), a charming heroin ( Janine Turner ), and one of the most darstardy bunch of villains ever ( priceless John Lithgow and deceivingly feminine Caroline Goodall, but also Rex Linn - in a longer than usual part and who makes the most of it, Leon, Craig Fairbrass ) Good, solid entertainment then , if no credibility.As Roger Ebert wrote ( about another film )\"It\\'s the kind of movie you can sit back and enjoy as long as you don\\'t make the mistake of thinking too much.\"<br /><br />'\n",
            " ...\n",
            " 'Bare Wench is another softcore parody of the Blair Witch project (I think there\\'s about two dozen of those things out there). It has 5 very attractive women (which includes Nikki Fritz, Julie Smith, and Julie Strain), and one dorky guy whose only purpose is to provide comic relief.<br /><br />Okay, so I\\'m thinking \"Cool. Great looking women, having softcore lesbian sex with each other very 10 minutes or so. This should be real good.\"<br /><br />Unfortunately, the producers blew it. There is nothing in this video that actually qualifies as a sex scene. There\\'s a couple of false starts, but the majority of the action is just the women posing for the camera. I guess once the producers had spent their money on the women, and spent more getting them to remove their clothes, they didn\\'t have any money left to get them to actually do anything. And I guess they also used up all their alloted nudity time too early, because towards the end of the video, there is a huge amount of pointless dialogue that is obviously being used for no other reason than to pad out the run time. \"You\\'re a liar! No you are! You go into the cave! No you go! I think we should go home! Well, I don\\'t!\" This goes on and on and on forever.<br /><br />There\\'s way better stuff than this.'\n",
            " 'Frank Langella steals my heart in everything he has ever been in! I love watching him!! i was 10 yrs old (1979) when i seen him for the first time.i eagerly await each and everything he\\'ll be acting in. hopefully one day i can see him in person. he\\'s very hypnotic and mysterious and that voice is commanding and strong! he is very attractive, even now at 65 he is absolutely stunning!!!! In my opinion he is the greatest actor iv\\'e ever seen! i adored him in \"Dracula\" ( along with a lot of other girls out there) and in \"god created woman\",\"house of D\",\"Jason and the argonauts\" and many more. i thought he was genius!!!!!! can\\'t wait to see him in \"good night and good luck\"'\n",
            " 'This SOFT soft-core/sci-fi B-movie is what you\\'d have if you took an early Fred Olen Ray film and took out the fun. Or conversely, it\\'s like an Uwe Boll \\'movie\\' but without as much ineptitude. A young nubile chain-gang convict (C.C. Costigan) agrees to pose as a space marshal in order to stop wacky Kim Dawson\\'s plans of...having everyone have sex with everyone else apparently (that vile fiend). Anyone who went into this film looking for serious science fiction, well you got what you deserved for not doing any homework on the film at all. First of all when did Kim Dawson EVER star in anything other than soft-core Skinamax level crap. For that matter take a look at the resume\\'s for Costigan and the Director before you take a hissy fit saying you expected something else. Don\\'t get me wrong, for a space/action/soft-core/titillation flick, this film is STILL not good, but if you expected something along the lines of \"Contact\", I DO NOT pity you.<br /><br />My Grade: D- <br /><br />Where I Saw it: Starz-on-demand (Available until December 8th, 2005)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru_5ODsH31Fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca37649-3bbc-4ac6-a930-51b6bb5c6d12"
      },
      "source": [
        "x_all_review=encode(all_data.review.values)\n",
        "x_masked_train,y_masked_labels,sample_weights=get_masked_input_and_labels(x_all_review)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False False False False False False  True False  True False\n",
            "  True False False False False False False False False False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            " False False False False False False False False False False False False\n",
            "  True  True False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "[False False False False False False False False False False False False\n",
            " False False False False  True False False False False False  True False\n",
            "  True  True False False False False False False False False False  True\n",
            " False False  True False False False False False False False False False\n",
            " False False False False False False False False False False False  True\n",
            " False False False False False False False False False False False False\n",
            " False False False False  True False  True False False False  True False\n",
            " False False  True False  True False False False False False False False\n",
            " False False False False False False False False False  True False False\n",
            " False False False False  True False False False False False  True False\n",
            " False  True False False False False False False False  True False False\n",
            " False False False False False False False False False False False False\n",
            "  True  True False False False False False False False False False False\n",
            " False  True False False False  True False False False False False False\n",
            " False False False False False False  True  True False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO77D_hvaqwk",
        "outputId": "e0239f45-ed59-4741-902d-4e02d58ded99"
      },
      "source": [
        "mask_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2368"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVz1szTx7S_s",
        "outputId": "eb7aa64e-0262-4f14-b819-fae0a689f07a"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  923,  2782,    19,    15,   457,     3,  4072,   114,     2,\n",
              "         283,   274,   100,   527,  1168,   210,   138,     2,   424,\n",
              "          19,  3214,   247,    76,   668,     6,   676,  2201,     3,\n",
              "        2825,  4914,    14,    34,    23,   632,    73,    64,    48,\n",
              "           7,   164,    20,     8,    63,  2373,     3,    86,    34,\n",
              "         183,   114,    34,    23,    30,     2,   549,     2,   497,\n",
              "           5,   632,     7,     4,  4881,    16,   129,     1,  2124,\n",
              "        1942,   465,     8,    46,    96,    48,   492,    62,  3214,\n",
              "          16,     7,    21,    48,    34,    66,  1798,  3214,    18,\n",
              "          16,  1173,     8,    63,   465,     3,    33,  1035,    35,\n",
              "          63,   905,   680,     3,  1964,  1433,   632,   157,    90,\n",
              "          31,   233,   351,  1158,     2,   196,     1,   632,  1230,\n",
              "         261,     6,    33,   125,    50,    34,  2413,    75,     8,\n",
              "           2,   750,     5,   137,   196,  1108,     3,    37,  1805,\n",
              "          12,    29,   154,     8,     4,  1013,    96,    28,     5,\n",
              "          54,   502,    94,     5,    31,    59,    32,  1202,   172,\n",
              "       15287,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIiCzDNsdGRC",
        "outputId": "480558ab-b2c4-4dfc-907b-35952356fa5d"
      },
      "source": [
        "print(sample_weights[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0jOBVaw4OEr",
        "outputId": "c9be6da0-3893-49b3-83dd-7a5f1eea3ae2"
      },
      "source": [
        "x_masked_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  923,   634,    19,    15,   457,     3,  4072,   114,     2,\n",
              "         283,   274,   100,   527,  1168,   210,   138,     2,   424,\n",
              "          19,  3214,   247,    76,   668,  2368,   676,  2201,     3,\n",
              "        2825,  4914,  2368,    34,    23,   632,    73,    64,  2368,\n",
              "           7,   164,    20,  2368,    63,  2373,     3,    86,    34,\n",
              "         183,   114,  2368,    23,    30,     2,   549,     2,   497,\n",
              "           5,   632,     7,     4,  4881,    16,  2275,     1,  2124,\n",
              "        1942,   465,     8,    46,    96,    48,   492,    62,  3214,\n",
              "          16,     7,    21,    48,    34,    66,  1798,  3214,    18,\n",
              "          16,  1173,     8,  2368,   465,     3,    33,  1035,    35,\n",
              "          63,   905,   680,     3,  1964,  1433,   632,   157,    90,\n",
              "          31,   233,   351,  1158,     2,   196,     1,   632,  1230,\n",
              "         261,     6,    33,   125,    50,    34,  2368,    75,     8,\n",
              "           2,   750,     5,   137,   196,  2368,     3,    37,  1805,\n",
              "          12,    29,   154,     8,  2368,  1013,    96,  2368,     5,\n",
              "          54,   502,    94,     5,    31,    59,    32,  1202,   172,\n",
              "       15287,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIHVAmjbeAAI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXtNqb-c46aI",
        "outputId": "ad25d326-0f24-484a-cb96-043f91e2bf23"
      },
      "source": [
        "y_masked_labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  923,  2782,    19,    15,   457,     3,  4072,   114,     2,\n",
              "         283,   274,   100,   527,  1168,   210,   138,     2,   424,\n",
              "          19,  3214,   247,    76,   668,     6,   676,  2201,     3,\n",
              "        2825,  4914,    14,    34,    23,   632,    73,    64,    48,\n",
              "           7,   164,    20,     8,    63,  2373,     3,    86,    34,\n",
              "         183,   114,    34,    23,    30,     2,   549,     2,   497,\n",
              "           5,   632,     7,     4,  4881,    16,   129,     1,  2124,\n",
              "        1942,   465,     8,    46,    96,    48,   492,    62,  3214,\n",
              "          16,     7,    21,    48,    34,    66,  1798,  3214,    18,\n",
              "          16,  1173,     8,    63,   465,     3,    33,  1035,    35,\n",
              "          63,   905,   680,     3,  1964,  1433,   632,   157,    90,\n",
              "          31,   233,   351,  1158,     2,   196,     1,   632,  1230,\n",
              "         261,     6,    33,   125,    50,    34,  2413,    75,     8,\n",
              "           2,   750,     5,   137,   196,  1108,     3,    37,  1805,\n",
              "          12,    29,   154,     8,     4,  1013,    96,    28,     5,\n",
              "          54,   502,    94,     5,    31,    59,    32,  1202,   172,\n",
              "       15287,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otqf5Wun4-Uz",
        "outputId": "41625c53-b61f-4925-d7da-f7bf258f9146"
      },
      "source": [
        "sample_weights[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXSDlCvY5KCA"
      },
      "source": [
        "aa=np.random.rand(25000,256)<0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0lNqg927mQ4",
        "outputId": "92af3d0f-26b9-4958-923b-b21b4424df65"
      },
      "source": [
        "aa\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False,  True, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ...,  True, False, False],\n",
              "       [False,  True, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False,  True, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC7zaOvY8eHD",
        "outputId": "2a76efa0-bc3c-4c0d-c7a9-8eb85ca322a7"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  923,  2782,    19,    15,   457,     3,  4072,   114,     2,\n",
              "         283,   274,   100,   527,  1168,   210,   138,     2,   424,\n",
              "          19,  3214,   247,    76,   668,     6,   676,  2201,     3,\n",
              "        2825,  4914,    14,    34,    23,   632,    73,    64,    48,\n",
              "           7,   164,    20,     8,    63,  2373,     3,    86,    34,\n",
              "         183,   114,    34,    23,    30,     2,   549,     2,   497,\n",
              "           5,   632,     7,     4,  4881,    16,   129,     1,  2124,\n",
              "        1942,   465,     8,    46,    96,    48,   492,    62,  3214,\n",
              "          16,     7,    21,    48,    34,    66,  1798,  3214,    18,\n",
              "          16,  1173,     8,    63,   465,     3,    33,  1035,    35,\n",
              "          63,   905,   680,     3,  1964,  1433,   632,   157,    90,\n",
              "          31,   233,   351,  1158,     2,   196,     1,   632,  1230,\n",
              "         261,     6,    33,   125,    50,    34,  2413,    75,     8,\n",
              "           2,   750,     5,   137,   196,  1108,     3,    37,  1805,\n",
              "          12,    29,   154,     8,     4,  1013,    96,    28,     5,\n",
              "          54,   502,    94,     5,    31,    59,    32,  1202,   172,\n",
              "       15287,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH5ILTNJeFRN",
        "outputId": "51fa2898-13f1-4419-a06c-2fbdeb0edf47"
      },
      "source": [
        "y_masked_labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  923,  2782,    19,    15,   457,     3,  4072,   114,     2,\n",
              "         283,   274,   100,   527,  1168,   210,   138,     2,   424,\n",
              "          19,  3214,   247,    76,   668,     6,   676,  2201,     3,\n",
              "        2825,  4914,    14,    34,    23,   632,    73,    64,    48,\n",
              "           7,   164,    20,     8,    63,  2373,     3,    86,    34,\n",
              "         183,   114,    34,    23,    30,     2,   549,     2,   497,\n",
              "           5,   632,     7,     4,  4881,    16,   129,     1,  2124,\n",
              "        1942,   465,     8,    46,    96,    48,   492,    62,  3214,\n",
              "          16,     7,    21,    48,    34,    66,  1798,  3214,    18,\n",
              "          16,  1173,     8,    63,   465,     3,    33,  1035,    35,\n",
              "          63,   905,   680,     3,  1964,  1433,   632,   157,    90,\n",
              "          31,   233,   351,  1158,     2,   196,     1,   632,  1230,\n",
              "         261,     6,    33,   125,    50,    34,  2413,    75,     8,\n",
              "           2,   750,     5,   137,   196,  1108,     3,    37,  1805,\n",
              "          12,    29,   154,     8,     4,  1013,    96,    28,     5,\n",
              "          54,   502,    94,     5,    31,    59,    32,  1202,   172,\n",
              "       15287,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wE6b3WX8ls4"
      },
      "source": [
        "labb=-1*np.ones((5,5),dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BfalK3e9Xuk"
      },
      "source": [
        "c=[[11,22,33,44,55],\n",
        "   [2,3,4,5,6],\n",
        "   [3,4,5,6,7],\n",
        "   [4,5,6,7,8],\n",
        "   [5,6,7,8,9]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAGznf4j8vWq"
      },
      "source": [
        "ab=np.random.rand(5,5)<0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYYEBW10_3FQ",
        "outputId": "c76ca6e7-4981-47de-8217-38d9ce5c1de4"
      },
      "source": [
        "labb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1, -1, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIfUwiPz80ph",
        "outputId": "759af870-d765-49af-a4ee-82cee93afe79"
      },
      "source": [
        "ab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False,  True, False, False],\n",
              "       [False, False, False, False, False],\n",
              "       [False, False, False, False, False],\n",
              "       [False, False, False, False, False],\n",
              "       [False, False, False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YTYFiK5S1Pd",
        "outputId": "bf4bb8b6-7116-49e1-9968-d6b7fa062d1b"
      },
      "source": [
        "ab.astype(int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8_YrKDoS5M-",
        "outputId": "1fc1d6a1-c7ba-4966-f870-33ff4d03ee20"
      },
      "source": [
        "c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11, 22, 33, 44, 55],\n",
              " [2, 3, 4, 5, 6],\n",
              " [3, 4, 5, 6, 7],\n",
              " [4, 5, 6, 7, 8],\n",
              " [5, 6, 7, 8, 9]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40ZJljxfTEdq",
        "outputId": "bfe2f71e-4a1d-40c3-cdfe-ee2aa8ce40f5"
      },
      "source": [
        "labb[ab]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US_StLxTShFp",
        "outputId": "df293836-b4f6-40b4-ddec-35ed4fec3785"
      },
      "source": [
        "labb[ab.astype(int)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1]],\n",
              "\n",
              "       [[-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1]],\n",
              "\n",
              "       [[-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1]],\n",
              "\n",
              "       [[-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1]],\n",
              "\n",
              "       [[-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-INkmwW7Fyo",
        "outputId": "3b8a4c10-83bd-45d4-bff7-bc0949a3353c"
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.5.0.dev20201213)\n",
            "Requirement already satisfied: tb-nightly~=2.5.0.a in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.5.0a20201213)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: tf-estimator-nightly~=2.5.0.dev in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.5.0.dev2020121301)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.19.4)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.36.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.32.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (50.3.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from h5py~=3.1.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2020.12.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCsnj03W79Ha",
        "outputId": "955704a5-59ec-4aec-8bf7-93672075e5a3"
      },
      "source": [
        "def bert_module(query, key, value, i):\n",
        "    # Multi headed self-attention\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=config.NUM_HEAD,\n",
        "        key_dim=config.EMBED_DIM // config.NUM_HEAD,\n",
        "        name=\"encoder_{}/multiheadattention\".format(i),\n",
        "    )(query, key, value)\n",
        "    attention_output = layers.Dropout(0.1, name=\"encoder_{}/att_dropout\".format(i))(\n",
        "        attention_output\n",
        "    )\n",
        "    attention_output = layers.LayerNormalization(\n",
        "        epsilon=1e-6, name=\"encoder_{}/att_layernormalization\".format(i)\n",
        "    )(query + attention_output)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ffn = keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(config.FF_DIM, activation=\"relu\"),\n",
        "            layers.Dense(config.EMBED_DIM),\n",
        "        ],\n",
        "        name=\"encoder_{}/ffn\".format(i),\n",
        "    )\n",
        "    ffn_output = ffn(attention_output)\n",
        "    ffn_output = layers.Dropout(0.1, name=\"encoder_{}/ffn_dropout\".format(i))(\n",
        "        ffn_output\n",
        "    )\n",
        "    sequence_output = layers.LayerNormalization(\n",
        "        epsilon=1e-6, name=\"encoder_{}/ffn_layernormalization\".format(i)\n",
        "    )(attention_output + ffn_output)\n",
        "    return sequence_output\n",
        "\n",
        "\n",
        "def get_pos_encoding_matrix(max_len, d_emb):\n",
        "    pos_enc = np.array(\n",
        "        [\n",
        "            [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)]\n",
        "            if pos != 0\n",
        "            else np.zeros(d_emb)\n",
        "            for pos in range(max_len)\n",
        "        ]\n",
        "    )\n",
        "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])  # dim 2i\n",
        "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])  # dim 2i+1\n",
        "    return pos_enc\n",
        "\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
        "    reduction=tf.keras.losses.Reduction.NONE\n",
        ")\n",
        "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "\n",
        "class MaskedLanguageModel(tf.keras.Model):\n",
        "    def train_step(self, inputs):\n",
        "        if len(inputs) == 3:\n",
        "            features, labels, sample_weight = inputs\n",
        "        else:\n",
        "            features, labels = inputs\n",
        "            sample_weight = None\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(features, training=True)\n",
        "            loss = loss_fn(labels, predictions, sample_weight=sample_weight)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Compute our own metrics\n",
        "        loss_tracker.update_state(loss, sample_weight=sample_weight)\n",
        "\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [loss_tracker]\n",
        "\n",
        "\n",
        "def create_masked_language_bert_model():\n",
        "    inputs = layers.Input((config.MAX_LEN,), dtype=tf.int64)\n",
        "\n",
        "    word_embeddings = layers.Embedding(\n",
        "        config.VOCAB_SIZE, config.EMBED_DIM, name=\"word_embedding\"\n",
        "    )(inputs)\n",
        "    position_embeddings = layers.Embedding(\n",
        "        input_dim=config.MAX_LEN,\n",
        "        output_dim=config.EMBED_DIM,\n",
        "        weights=[get_pos_encoding_matrix(config.MAX_LEN, config.EMBED_DIM)],\n",
        "        name=\"position_embedding\",\n",
        "    )(tf.range(start=0, limit=config.MAX_LEN, delta=1))\n",
        "    embeddings = word_embeddings + position_embeddings\n",
        "\n",
        "    encoder_output = embeddings\n",
        "    for i in range(config.NUM_LAYERS):\n",
        "        encoder_output = bert_module(encoder_output, encoder_output, encoder_output, i)\n",
        "\n",
        "    mlm_output = layers.Dense(config.VOCAB_SIZE, name=\"mlm_cls\", activation=\"softmax\")(\n",
        "        encoder_output\n",
        "    )\n",
        "    mlm_model = MaskedLanguageModel(inputs, mlm_output, name=\"masked_bert_model\")\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=config.LR)\n",
        "    mlm_model.compile(optimizer=optimizer)\n",
        "    return mlm_model\n",
        "\n",
        "\n",
        "id2token = dict(enumerate(vectorize_layer.get_vocabulary()))\n",
        "token2id = {y: x for x, y in id2token.items()}\n",
        "\n",
        "\n",
        "class MaskedTextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self, sample_tokens, top_k=5):\n",
        "        self.sample_tokens = sample_tokens\n",
        "        self.k = top_k\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        return \" \".join([id2token[t] for t in tokens if t != 0])\n",
        "\n",
        "    def convert_ids_to_tokens(self, id):\n",
        "        return id2token[id]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        prediction = self.model.predict(self.sample_tokens)\n",
        "\n",
        "        masked_index = np.where(self.sample_tokens == mask_token_id)\n",
        "        masked_index = masked_index[1]\n",
        "        mask_prediction = prediction[0][masked_index]\n",
        "\n",
        "        top_indices = mask_prediction[0].argsort()[-self.k :][::-1]\n",
        "        values = mask_prediction[0][top_indices]\n",
        "\n",
        "        for i in range(len(top_indices)):\n",
        "            p = top_indices[i]\n",
        "            v = values[i]\n",
        "            tokens = np.copy(sample_tokens[0])\n",
        "            tokens[masked_index[0]] = p\n",
        "            result = {\n",
        "                \"input_text\": self.decode(sample_tokens[0].numpy()),\n",
        "                \"prediction\": self.decode(tokens),\n",
        "                \"probability\": v,\n",
        "                \"predicted mask token\": self.convert_ids_to_tokens(p),\n",
        "            }\n",
        "            pprint(result)\n",
        "\n",
        "\n",
        "sample_tokens = vectorize_layer([\"I have watched this [mask] and it was awesome\"])\n",
        "generator_callback = MaskedTextGenerator(sample_tokens.numpy())\n",
        "\n",
        "bert_masked_model = create_masked_language_bert_model()\n",
        "bert_masked_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"masked_bert_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_embedding (Embedding)      (None, 256, 128)     3840000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 256, 128)     0           word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/multiheadattention (M (None, 256, 128)     66048       tf.__operators__.add_1[0][0]     \n",
            "                                                                 tf.__operators__.add_1[0][0]     \n",
            "                                                                 tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/att_dropout (Dropout) (None, 256, 128)     0           encoder_0/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 256, 128)     0           tf.__operators__.add_1[0][0]     \n",
            "                                                                 encoder_0/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn (Sequential)      (None, 256, 128)     33024       encoder_0/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_0/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 256, 128)     0           encoder_0/att_layernormalization[\n",
            "                                                                 encoder_0/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mlm_cls (Dense)                 (None, 256, 30000)   3870000     encoder_0/ffn_layernormalization[\n",
            "==================================================================================================\n",
            "Total params: 7,809,584\n",
            "Trainable params: 7,809,584\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfVBK2rb-sP9"
      },
      "source": [
        "x_all_review = encode(all_data.review.values)\n",
        "x_masked_train, y_masked_labels, sample_weights = get_masked_input_and_labels(\n",
        "    x_all_review\n",
        ")\n",
        "\n",
        "mlm_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_masked_train, y_masked_labels, sample_weights)\n",
        ")\n",
        "mlm_ds = mlm_ds.shuffle(1000).batch(config.BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P15sTdLAZQf",
        "outputId": "6d970ee3-e4e1-46b9-df97-cc35e9667a60"
      },
      "source": [
        "next(iter(mlm_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 256), dtype=int64, numpy=\n",
              " array([[2368,  416,  143, ...,    0,    0,    0],\n",
              "        [  10,   68,   64, ...,    0,    0,    0],\n",
              "        [  11, 9410,    5, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [2368,  279,   10, ...,    0,    0,    0],\n",
              "        [   2,   17,    7, ...,    2, 2038,    3],\n",
              "        [  10, 2368, 1191, ...,    0,    0,    0]])>,\n",
              " <tf.Tensor: shape=(32, 256), dtype=int64, numpy=\n",
              " array([[1611,  416,  143, ...,    0,    0,    0],\n",
              "        [  10,   68,   64, ...,    0,    0,    0],\n",
              "        [  11, 9410,    5, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [  60,  279,   10, ...,    0,    0,    0],\n",
              "        [   2,   17,    7, ...,    2, 1080,    3],\n",
              "        [  10,  229, 1191, ...,    0,    0,    0]])>,\n",
              " <tf.Tensor: shape=(32, 256), dtype=float64, numpy=\n",
              " array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 1., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.]])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDsqV66WAqRl",
        "outputId": "7dc45ecd-b623-4f0b-99ed-1a21f7d7842e"
      },
      "source": [
        "y_masked_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  923,  2782,    19, ...,     0,     0,     0],\n",
              "       [   11,   213,    25, ...,     0,     0,     0],\n",
              "       [  802,  2886,    22, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [ 3758, 17382,     7, ...,     0,     0,     0],\n",
              "       [ 1263, 16414,  2168, ...,     0,     0,     0],\n",
              "       [   11,  2271,     1, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BOUYTJIB7iD",
        "outputId": "a54ee677-dcda-4a08-9d31-a5141fcefd70"
      },
      "source": [
        "mask_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2368"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcXdAU8M_23g",
        "outputId": "9fd474e0-f450-4d22-9bf3-eafb4a8ad25c"
      },
      "source": [
        "x_masked_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  923,  1587,  2368,    15,   457,  2368,  4072,   114,     2,\n",
              "         283,   274,   100,   527,  1168,   210,  2368,     2,  2368,\n",
              "          19,  3214,   247,    76,   668,     6,   676,  2201,     3,\n",
              "        2368,  4914,    14,    34,    23,   632,    73,  2368,    48,\n",
              "           7,   164,    20,     8,    63,  2373,  2368,    86,    34,\n",
              "         183,  2368,    34,    23,    30,     2,   549,     2,   497,\n",
              "           5,  2368,     7,     4,  4881,    16,   129,     1,  2124,\n",
              "        1942,  2368,     8,    46,    96,    48,   492,    62,  3214,\n",
              "          16,     7,    21,  2368,   747,    66,  1698,  3214,    18,\n",
              "          16,  1173,     8,    63,   465,     3,    33,  1035,    35,\n",
              "        2368,   905,   680,     3,  1964,  1433,   632,   157,    90,\n",
              "          31,   233,   351,  1158,     2,   196,     1,   632,  1230,\n",
              "         261,     6,  2368,   125,    50,    34,  2413,  1800,     8,\n",
              "           2,  2368,     5,  2368,   196,  1108,     3,    37,  1805,\n",
              "          12,    29,  2368,     8,     4,  1013,    96,  2368,     5,\n",
              "          54,   502,    94,  2368,    31,    59,    32,  1202,   172,\n",
              "       15287,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "sNNU98po8HOx",
        "outputId": "baf983ed-2b00-419c-f0af-1d32b2d01bcd"
      },
      "source": [
        "bert_masked_model.fit(mlm_ds, epochs=5, callbacks=[generator_callback])\n",
        "bert_masked_model.save(\"bert_mlm_imdb.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "  45/1563 [..............................] - ETA: 2:30:10 - loss: 8.2065"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-bf15de2f5313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_masked_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlm_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerator_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbert_masked_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert_mlm_imdb.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 _r=1):\n\u001b[1;32m   1131\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2970\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2971\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2972\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1946\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1948\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1949\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1950\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku3_TGH69rpD"
      },
      "source": [
        "mlm_model = keras.models.load_model(\n",
        "    \"bert_mlm_imdb.h5\", custom_objects={\"MaskedLanguageModel\": MaskedLanguageModel}\n",
        ")\n",
        "pretrained_bert_model = tf.keras.Model(\n",
        "    mlm_model.input, mlm_model.get_layer(\"encoder_0/ffn_layernormalization\").output\n",
        ")\n",
        "\n",
        "# Freeze it\n",
        "pretrained_bert_model.trainable = False\n",
        "\n",
        "\n",
        "def create_classifier_bert_model():\n",
        "    inputs = layers.Input((config.MAX_LEN,), dtype=tf.int64)\n",
        "    sequence_output = pretrained_bert_model(inputs)\n",
        "    pooled_output = layers.GlobalMaxPooling1D()(sequence_output)\n",
        "    hidden_layer = layers.Dense(64, activation=\"relu\")(pooled_output)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
        "    classifer_model = keras.Model(inputs, outputs, name=\"classification\")\n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    classifer_model.compile(\n",
        "        optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return classifer_model\n",
        "\n",
        "\n",
        "classifer_model = create_classifier_bert_model()\n",
        "classifer_model.summary()\n",
        "\n",
        "# Train the classifier with frozen BERT stage\n",
        "classifer_model.fit(\n",
        "    train_classifier_ds,\n",
        "    epochs=5,\n",
        "    validation_data=test_classifier_ds,\n",
        ")\n",
        "\n",
        "# Unfreeze the BERT model for fine-tuning\n",
        "pretrained_bert_model.trainable = True\n",
        "optimizer = keras.optimizers.Adam()\n",
        "classifer_model.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "classifer_model.fit(\n",
        "    train_classifier_ds,\n",
        "    epochs=5,\n",
        "    validation_data=test_classifier_ds,"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}